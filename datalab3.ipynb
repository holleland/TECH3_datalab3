{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d969bf4-0c41-46d4-9ddc-58101fa78b20",
   "metadata": {},
   "source": [
    "# Datalab 3\n",
    "In module 3, you have learned to generate random numbers, do monte carlo simulations and bootstrap. You have also learned about estimators and the properties we want these to have: Unbiasedness and consistency. In this datalab, we will train abit more on these elements. We will use the maximum likelihood estimator of the exponential distribution as the running example. \n",
    "\n",
    "## Maximum likelihood estimator of the exponential distribution\n",
    "The benefit of simulating data is that we have full control of the data-generating process. If we have observed some data, we may assume a distribution. When we generate (or simulate) data, we know the distribution.\n",
    "\n",
    "In the lecture, we have seen that $1/\\bar x$ is the maximum likelihood estimator for $\\lambda$ in the exponential distribution. That is, $\\hat\\lambda =1/ \\bar x$. In the documentation for *scipy.stats.expon* it says that *\"A common parameterization for expon is in terms of the rate parameter lambda, such that pdf = lambda * exp(-lambda * x). This parameterization corresponds to using scale = 1 / lambda.\"* This corresponds to the parametrization we have considered $$f(x) = \\lambda e^{-\\lambda x},\\quad x>0.$$ Assume that the true $\\lambda$ is 5. We can generate a sample of size 10 from this distribution by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65854906-e2c0-4069-a1fa-ed8b4b4378cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "n=10\n",
    "np.random.seed(123)\n",
    "x = stats.expon.rvs(size = n, scale = 1/5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13469b7-2e79-4b3c-9bf4-9c248ef168fb",
   "metadata": {},
   "source": [
    "If we calculate the maximum likelihood estimator, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c51a10b-77b3-4e3a-82d1-4a8884a604b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambdahat = 1/x.mean()\n",
    "print(lambdahat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5657742-adab-4466-84b0-52497e35cd1f",
   "metadata": {},
   "source": [
    "As we saw in the lecture, this is a biased estimator. When the sample size increase, it is asymptoically unbiased, but for small samples we have a biased estimator. The expected value of $$\\hat\\lambda= \\frac{n}{n-1}\\lambda.$$ Let us try to bias-correct the estimator! What if we instead use $$\\tilde\\lambda = \\frac{n-1}{n}\\hat\\lambda$$ as our estimator? Then the expected value of $\\tilde\\lambda$ is\n",
    "$$E(\\tilde\\lambda) =  \\frac{n-1}{n}E(\\hat\\lambda) =  \\frac{n-1}{n} \\frac{n}{n-1}\\lambda = \\lambda,$$\n",
    "hence the estimator is unbiased! We also have that \n",
    "$$Var(\\tilde\\lambda) = \\frac{(n-1)^2}{n^2}Var(\\hat\\lambda)<Var(\\hat\\lambda). $$\n",
    "It seems we will get a better estimator both in terms of bias and uncertainty of the estimator, by a lower variance! We can have our cake and eat it too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72cb76-6322-4579-900e-a1a15e81ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdatilde = lambdahat * (n-1)/n\n",
    "print(lambdatilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83f8b1-e5d2-48a6-9244-c8aa10ed36d2",
   "metadata": {},
   "source": [
    "We can use Monte Carlo simulations to confirm what the calculations above have told us! Let us simulate 10,000 samples of size ten, and calculate the two estimators. This will give us the sampling distribution of the two estimators. Since we know the true value (lambda = 5), we can also calculate the bias by $E(\\hat\\lambda)-5$, or just compare the expected value to the true value of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa938f17-ded8-4450-a29e-7d6279de8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "n_sim = 10000 # number of simulations\n",
    "# generate 10,000 samples of size 10: \n",
    "mc_samples = stats.expon.rvs(size=(n_sim, n), scale=1/5)\n",
    "# Calculate 10,000 mean values: \n",
    "sample_means = np.mean(mc_samples, axis=1)\n",
    "# Calculate 10,000 estimates: \n",
    "lambda_hats = 1 / sample_means\n",
    "lambda_tildes = lambda_hats * (n - 1) / n\n",
    "# Estimate bias:\n",
    "print(\"Expected value of MLE: \", lambda_hats.mean())\n",
    "print(\"Expected value of bias-corrected MLE: \", lambda_tildes.mean())\n",
    "print(\"Standard deviation of MLE: \", lambda_hats.std())\n",
    "print(\"Standard deviation of bias-corrected MLE: \", lambda_tildes.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb619a03-d099-48bf-a8df-b36d73925986",
   "metadata": {},
   "source": [
    "As can be seen from the output, the Monte-Carlo estimated expected value of the bias-corrected MLE is much closer to 5 than the MLE. We also see that the standard deviation of $\\tilde\\lambda$ is lower than that of $\\hat\\lambda$. Usually, we must pay for lower bias with increased variance, but not in this case! We can also plot the two sampling distributions. We can add a normal curve to see if the normal approximation is any good for such a low sample size. Note that these estimators are based on $1/\\bar X$. The central limit theorem applies to $\\bar X$. We can therefore not use it directly to say that $\\tilde\\lambda$ and $\\hat\\lambda$ will be asymptotically normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a4510-3e74-4527-b7b9-5c2fff2bb5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "true_lambda = 5\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Histogram for lambda_hat\n",
    "plt.hist(lambda_hats, bins=100, density=True, \n",
    "         alpha=0.5, label=r'$\\hat{\\lambda}$')\n",
    "\n",
    "# Histogram for lambda_tilde\n",
    "plt.hist(lambda_tildes, bins=100, density=True, \n",
    "         alpha=0.5, label=r'$\\tilde{\\lambda}$')\n",
    "# Create x-grid for normal curves\n",
    "x_vals = np.linspace(\n",
    "    min(lambda_tildes.min(), lambda_hats.min()),\n",
    "    max(lambda_tildes.max(), lambda_hats.max()),\n",
    "    500\n",
    ")\n",
    "\n",
    "# Normal approximation for MLE\n",
    "normal_hat = stats.norm.pdf(\n",
    "    x_vals,\n",
    "    loc=lambda_hats.mean(),\n",
    "    scale=lambda_hats.std()\n",
    ")\n",
    "\n",
    "# Normal approximation for bias-corrected\n",
    "normal_tilde = stats.norm.pdf(\n",
    "    x_vals,\n",
    "    loc=lambda_tildes.mean(),\n",
    "    scale=lambda_tildes.std()\n",
    ")\n",
    "\n",
    "# Plot normal curves\n",
    "plt.plot(x_vals, normal_hat, linewidth=2,\n",
    "         label=r'Normal approx $\\hat{\\lambda}$')\n",
    "\n",
    "plt.plot(x_vals, normal_tilde, linewidth=2,\n",
    "         linestyle='--',\n",
    "         label=r'Normal approx $\\tilde{\\lambda}$')\n",
    "\n",
    "# Vertical line at true lambda\n",
    "plt.axvline(true_lambda, color='black', linestyle='--', \n",
    "            linewidth=2, label=r'True $\\lambda = 5$')\n",
    "\n",
    "plt.xlabel(\"Estimate value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Sampling Distributions of Î» Estimators\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60beb1d8-3fe4-433a-95c4-1580d5d8e929",
   "metadata": {},
   "source": [
    "### Task\n",
    "Now, increase the sample size to 100. \n",
    "- How does the bias of the estimators change?\n",
    "- How the standard deviation change?\n",
    "- What about the normal approximation?\n",
    "\n",
    "What if you increase to n=1000?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5f16a-207e-4c9f-abeb-7b4d3e80d829",
   "metadata": {},
   "source": [
    "## Bootstrap\n",
    "Another way to check the properties of these estimators is by bootstrapping. Let us now just focus on the bias of the two estimators and assume that the first sample we generated is our dataset. Now, we can bootstrap the sampling distribution of $\\hat\\lambda$ by repeatedly sampling with replacement for the vector of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d62804-a421-442a-8832-09bae6fd66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_samples = 10000\n",
    "n=10\n",
    "np.random.seed(1234)\n",
    "x = stats.expon.rvs(size=n, scale=1/5) # Generate our data\n",
    "\n",
    "# Original estimates\n",
    "lambda_hat = 1 / x.mean()\n",
    "# Store estimates for the bootstrap samples: \n",
    "hat_boots = np.zeros(bootstrap_samples)\n",
    "\n",
    "# Loop of bootstrap: \n",
    "for b in range(bootstrap_samples):\n",
    "    # Bootstrap resample: \n",
    "    boot_sample = np.random.choice(x, size=n, replace=True)\n",
    "    # hatlambda for bootstrap sample: \n",
    "    hat_boots[b] = 1 / boot_sample.mean() \n",
    "# Print bias: \n",
    "print(\"Original estimate:\", lambda_hat)\n",
    "print(\"Original estimate bias:\", lambda_hat-5)\n",
    "print(\"Bootstrap bias:\", hat_boots.mean()-5)\n",
    "print(\"Bootstrap standard deviation:\", hat_boots.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6a7aa-930c-4e48-97d6-379a19738e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Histograms\n",
    "plt.hist(hat_boots, bins=60, density=True,\n",
    "         alpha=0.5, label=r'Bootstrap $\\hat{\\lambda}$')\n",
    "\n",
    "\n",
    "# Grid for normal curves\n",
    "x_vals = np.linspace(\n",
    "    hat_boots.min(),\n",
    "    hat_boots.max(),\n",
    "    500\n",
    ")\n",
    "\n",
    "# Normal approximations (bootstrap mean & sd)\n",
    "normal_hat = stats.norm.pdf(\n",
    "    x_vals,\n",
    "    loc=hat_boots.mean(),\n",
    "    scale=hat_boots.std()\n",
    ")\n",
    "\n",
    "\n",
    "plt.plot(x_vals, normal_hat, linewidth=2,\n",
    "         label=r'Normal approx $\\hat{\\lambda}$')\n",
    "\n",
    "\n",
    "# Vertical lines\n",
    "plt.axvline(lambda_hat, color='blue', linestyle='--',\n",
    "            linewidth=2, label=r'Original $\\hat{\\lambda}$')\n",
    "\n",
    "plt.axvline(true_lambda, color='black', linestyle=':',\n",
    "            linewidth=2, label=r'True $\\lambda$')\n",
    "\n",
    "plt.xlabel(\"Estimate value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Bootstrap Sampling Distributions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"25% percentile:\", np.percentile(hat_boots, 25))\n",
    "print(\"75% percentile:\", np.percentile(hat_boots, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107079c-a3fc-4080-84bf-a7f29a5cd9b3",
   "metadata": {},
   "source": [
    "Note that 10 is a quite low sample size. We get a high uncertainty of the estimators. The bias is roughly -1. Here the most interesting property we can get is the sampling distribution and perhaps the standard deviation of the estimator. If we make a 95% confidence interval based on the sampling distribution.\n",
    "\n",
    "\n",
    "## Task\n",
    "a) Find the 2.5% and 97.5th percentiles of the sampling distribution. Is the true value $\\lambda = 5$ included in the interval?\n",
    "b) Rerun the code with increasing sample size. How does this affect your conclusions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f256224-1502-4732-bcaf-53ffee492389",
   "metadata": {},
   "source": [
    "## Parametric bootstrap\n",
    "Now, another way to use this bootstrap estimate is to bootstrap the bias. If we assume we do not now the true value of $\\lambda$, but we want to estimate the bias. We could then turn to a parametric bootstrap. We assume that our data is generated from an exponential distribution, but we do not now parameter. We can then estimate the parameter from our sample, and use that to simulate new bootstrap samples from an exponential distribution. This is not the same as bootstrapping, because we generate new data. The technique is maybe more similar to Monte Carlo, except that we have estimated the parameters for this particular dataset. \n",
    "\n",
    "We will now only focus on $\\hat\\lambda$. We simulate 10,000 new datasets of size 10 using the estimate of $\\hat\\lambda$ as the true value. We estimate using the estimator $\\hat\\lambda$ on the 10,000 bootstrap samples and estimate the bias as the bootstrap average - original estimate (which is the true value for these generated data). We can then bias-correct the original estimate by \n",
    "\n",
    "$$\\hat\\lambda_{\\text{bias-correct}} = \\hat\\lambda - \\text{bias}_\\text{boot},$$\n",
    "where $$\\text{bias}_\\text{boot}= \\sum_{b=1}^B \\hat\\lambda_b - \\hat\\lambda.$$\n",
    "\n",
    "## Task\n",
    "- Implement this procedure. Is the bias correction improving the estimate?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
